{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWHlgbu9+gh1vBeECfEFlx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingtuler1454/torch/blob/main/5kab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Необходимо загрузить исходный набор данных и соответствующие метки классов.\n",
        "2.   Произвести разделение загруженного набора данных на обучающую, тестовую и валидационую выборки (в соотношении 80:10:10). Проверить, что сформированные выборки сбалансированы.\n",
        "3.   Написать модель нейронной сети для решения задачи классификации.\n",
        "4.   Описать пайплайн предобработки данных. **ВАЖНО**: что так как ваш вариант предполагает работу с текстом, то необходимо выполниить векторизацию данных (подробности в туториале).\n",
        "4.   Написать `train loop` (цикл обучения). Провести эксперименты по обучению с различными значениями параметров `learning rate` (скорость обучения) и `batch size` (размер мини-пакета). Выбрать по 3 значения для `learning rate` и `batch size` (итоговое количество экспериментов будет 9).\n",
        "5.   Для каждого проведенного эксперимента вывести графики для значения функции потерь (ось `x` - итерация обучения/номер эпохи; ось `y` - значение функции потерь) и выбранной метрики качества (ось `x` - итерация обучения/номер эпохи; ось `y` - значение метрики качества). Графики необходимо выводить как для обучающей, так и для валидационной выборки.\n",
        "6.   Оценить качество работы модели на тестовой выборке.\n",
        "7.   Сделайте выводы по полученным результатам проведенных экспериментов. Какую модель из всех полученных стоит использовать?\n",
        "8.   Сохранить обученную модель.\n",
        "9.   Выполните повторную инициализацию модели и загрузку весов.  Продемонстрируйте работоспособность модели (пропустите через нее какой-то отзыв/рецензию и выведите результат).\n",
        "\n",
        "\n",
        "https://www.kaggle.com/code/shivammehta007/spam-not-spam-classifier-with-pytorch"
      ],
      "metadata": {
        "id": "wP67NcnxYIcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EHRjiS4lXzLq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys5YlWVKpKTk",
        "outputId": "18fb71c9-d53c-4483-f629-bf14c3a6972e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8e87jTiphJ5",
        "outputId": "d397eda2-fb34-4b7f-9a84-2ba608dcd59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 19 17:22:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    26W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо загрузить исходный набор данных и соответствующие метки классов."
      ],
      "metadata": {
        "id": "Vbh4Td7HzMXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "with open(\"/content/number_star.txt\",\"r+\") as file:\n",
        "  number_star=file.read()\n",
        "  number_star=number_star.split(\", \")\n",
        "\n",
        "with open(\"/content/text_opinions.txt\",\"r+\") as file:\n",
        "  text_opinion=file.read()\n",
        "  text_opinion=text_opinion\n",
        "  text_opinion=text_opinion.split(\"', '\")"
      ],
      "metadata": {
        "id": "9ZiBobMfzamv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Произвести разделение загруженного набора данных на обучающую, тестовую и валидационую выборки (в соотношении 80:10:10). Проверить, что сформированные выборки сбалансированы."
      ],
      "metadata": {
        "id": "ASv3LNcIlAi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_opinion=text_opinion[0:240]\n",
        "train_star=number_star[0:240]\n",
        "train_opinion=train_opinion+text_opinion[1840:2080]\n",
        "train_star=train_star+number_star[1840:2080]\n",
        "train_opinion=train_opinion+text_opinion[2380:2620]\n",
        "train_star=train_star+number_star[2380:2620]\n",
        "train_opinion=train_opinion+text_opinion[2800:3040]\n",
        "train_star=train_star+number_star[2800:3040]\n",
        "train_opinion=train_opinion+text_opinion[3134:3374]\n",
        "train_star=train_star+number_star[3134:3374]\n",
        "\n",
        "\n",
        "test_opinion=text_opinion[240:270]\n",
        "test_star=number_star[240:270]\n",
        "test_opinion=test_opinion+text_opinion[2080:2110]\n",
        "test_star=test_star+number_star[2080:2110]\n",
        "test_opinion=test_opinion+text_opinion[2620:2650]\n",
        "test_star=test_star+number_star[2620:2650]\n",
        "test_opinion=test_opinion+text_opinion[3040:3070]\n",
        "test_star=test_star+number_star[3040:3070]\n",
        "test_opinion=test_opinion+text_opinion[3374:3370]\n",
        "test_star=test_star+number_star[3374:3370]\n",
        "\n",
        "\n",
        "valid_opinion=text_opinion[270:300]\n",
        "valid_star=number_star[270:300]\n",
        "valid_opinion+=text_opinion[2110:2140]\n",
        "valid_star+=number_star[2650:2680]\n",
        "valid_opinion+=text_opinion[2650:2680]\n",
        "valid_star+=number_star[3040:3070]\n",
        "valid_opinion+=text_opinion[3370:3400]\n",
        "valid_star+=number_star[3370:3400]"
      ],
      "metadata": {
        "id": "cSKFGsB7lBOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4cc1e7-45fd-440e-84e0-d54a6ecb1536"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написать модель нейронной сети для решения задачи классификации.\n"
      ],
      "metadata": {
        "id": "pWXZpyxPlkB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({\"star\": train_star, \"text\": train_opinion})\n",
        "\n",
        "remove_non_alphabets =lambda x: re.sub(r'[^а-яА-Я]',' ',x)\n",
        "tokenize = lambda x: word_tokenize(x)\n",
        "ps = PorterStemmer()\n",
        "stem = lambda w: [ ps.stem(x) for x in w ]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
      ],
      "metadata": {
        "id": "q2qtY6EwnEpO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'] = train_df['text'].apply(remove_non_alphabets)\n",
        "train_df['text'] = train_df['text'].apply(tokenize) # [ word_tokenize(row) for row in data['email']]\n",
        "train_df['text'] = train_df['text'].apply(stem)\n",
        "train_df['text'] = train_df['text'].apply(leammtizer)\n",
        "train_df['text'] = train_df['text'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "qrZXCie66oF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "cv = CountVectorizer(max_features=max_words, stop_words='english')\n",
        "sparse_matrix = cv.fit_transform(train_df['text'] ).toarray()\n",
        "sparse_matrix.shape\n",
        "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(train_df['text']))"
      ],
      "metadata": {
        "id": "lE9gsN9Y7N4q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear1 = nn.Linear(10000, 100)\n",
        "        self.linear2 = nn.Linear(100, 10)\n",
        "        self.linear3 = nn.Linear(10, 5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "model = LogisticRegression()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)\n",
        "x_train = Variable(torch.from_numpy(x_train)).float()\n",
        "y_train = Variable(torch.from_numpy(y_train)).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "ou1GmhpE7qKB",
        "outputId": "0073395e-9e22-4947-fbf9-2d436de028b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3c2a88c6eb78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
          ]
        }
      ]
    }
  ]
}